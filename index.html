<!-- <!DOCTYPE html> -->
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-PGZH8HT');</script>
  <!-- End Google Tag Manager -->

  <!-- Materialize - Compiled and minified CSS-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.95.3/css/materialize.min.css" />
  <!-- Font Awesome Icon - CSS-->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" />
  <!-- Custom Styles-->
  <link rel="stylesheet" href="./assets/css/style.css" />
  <title>Muhammad Naeem</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-126939217-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-126939217-2');
  </script>

  <!-- Open Graph-->
  <meta property="og:locale" content="en_US" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Muhammad Naeem" />
  <meta property="og:description" content="Software Developer" />
  <meta property="og:url" content="https://muhammadnaeem27.github.io/" />
  <meta property="og:site_name" content="Muhammad Naeem" />
  <meta property="article:publisher" content="https://muhammadnaeem27.github.io/" />
  <meta property="og:image" content="https://muhammadnaeem.github.io/examples/preview.JPG" />
  <!-- Twitter -->
  <meta name="description" content="Software Developer with a passion for backend development and artificial intelligence." />
  <link rel="apple-touch-icon" sizes="57x57" href="./assets/img/favicon/apple-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="60x60" href="./assets/img/favicon/apple-icon-60x60.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="./assets/img/favicon/apple-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="76x76" href="./assets/img/favicon/apple-icon-76x76.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="./assets/img/favicon/apple-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="120x120" href="./assets/img/favicon/apple-icon-120x120.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="./assets/img/favicon/apple-icon-144x144.png" />
  <link rel="apple-touch-icon" sizes="152x152" href="./assets/img/favicon/apple-icon-152x152.png" />
  <link rel="apple-touch-icon" sizes="180x180" href="./assets/img/favicon/apple-icon-180x180.png" />
  <link rel="icon" type="image/png" sizes="192x192" href="./assets/img/favicon/android-icon-192x192.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="./assets/img/favicon/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="96x96" href="./assets/img/favicon/favicon-96x96.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="./assets/img/favicon/favicon-16x16.png" />
  <link rel="manifest" href="./assets/img/favicon/manifest.json" />
  <meta name="msapplication-TileColor" content="#ffffff" />
  <meta name="msapplication-TileImage" content="./assets/img/favicon/ms-icon-144x144.png" />
  <meta name="theme-color" content="#ffffff" />
  <meta name="robots" content="index, follow" />
  <!-- Google Site Verification for indexing -->
  <meta name="google-site-verification" content="_qxK8tePiU2fhnwlwnJ7pkDFnj1k2EiKq_cYGy1Cb84" />
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PGZH8HT"
  height="0" width="0" style="display:none;visibility:hidden"></iframe>
  </noscript>
  
  <!-- Navigation Menu-->
  <!-- Nav class 1 -->
  <nav class="hide-on-small-only">
    <ul class="side-nav fixed section table-of-contents">

      <li class="logo">
        <a id="logo-container" aria-label="Navigate to the beginning of the page" href="#intro"
          class="brand-logo grey-blue-text">
          <img src="./assets/img/passport-new.png" class="circle img-responsive profile-pic" alt="avatar">
        </a>
      </li>

      <li class="bold">
        <a aria-label="Navigate to the About section" href="#about" class="waves-effect waves-dark teal-text"><i
            class="mdi-social-person small"></i><span>About</span></a>
      </li>
      <li class="bold">
        <a aria-label="Navigate to the Experience section" href="#experience"
          class="waves-effect waves-dark teal-text"><i
            class="mdi-action-trending-up small"></i><span>Experience</span></a>
      </li>

      <li class="bold">

        <a aria-label="Navigate to the Projects section" href="#projects" class="waves-effect waves-dark teal-text"><i
            class="mdi-av-my-library-books small"></i><span>Projects</span></a>
      </li>

      <li class="bold">

        <a aria-label="Navigate to the Skills section" href="#skills" class="waves-effect waves-dark teal-text"><i
            class="mdi-action-assessment small"></i><span>Skills</span></a>
      </li>
      
      <li class="bold">

        <a aria-label="Navigate to the Education section" href="#education" class="waves-effect waves-dark teal-text"><i
            class="mdi-social-school small"></i><span>Education</span></a>
      </li>

      <li class="bold">

        <a aria-label="Navigate to the Contact section" href="#contact" class="waves-effect waves-dark teal-text"><i
            class="mdi-content-mail small"></i><span>Contact</span></a>
      </li>

      <li class="bold">

        <a aria-label="Open Muhammad Naeem's resume in a new tab" href="https://drive.google.com/file/d/1TNTF1wbQFVPmvTHlU4esKBYUdIIYN7ZH/view?usp=sharing" target="_blank"
        class="waves-effect waves-dark teal-text"><i class="mdi-file-folder-open small"></i><span>Resume</span></a>  
      </li>
    </ul>
  </nav>

  <!-- Nav class 2 -->
  <nav class="hide-on-large only trigger z-depth-1">
    <a aria-label="Toggle visibility of the mobile navbar" href="#" data-activates="slide-out"
      class="button-collapse"><i class="mdi-navigation-menu"></i></a>
    <div class="name-title">
      <a id="name" aria-label="Navigate to the beginning of the page" href="#" class="teal-text">Muhammad Naeem</a><span class="black-text">Software Developer</span>
    </div>
  </nav>

  <!-- Nav class 3 -->
  <nav class="hide-on-large only">
    <ul id="slide-out" class="side-nav">
      <li class="bold">
        <a aria-label="Navigate to the About section" href="#about" class="waves-effect waves-dark teal-text"><i
            class="mdi-social-person small"></i><span>About</span></a>
      </li>
      <li class="bold">
        <a aria-label="Navigate to the Experience section" href="#experience"
          class="waves-effect waves-dark teal-text"><i
            class="mdi-action-trending-up small"></i><span>Experience</span></a>
      </li>
      <li class="bold">
        <a aria-label="Navigate to the Projects section" href="#projects" class="waves-effect waves-dark teal-text"><i
            class="mdi-av-my-library-books small"></i><span>Projects</span></a>
      </li>
      <li class="bold">
        <a aria-label="Navigate to the Skills section" href="#skills" class="waves-effect waves-dark teal-text"><i
            class="mdi-action-assessment small"></i><span>Skills</span></a>
      </li>

      <li class="bold">
        <a aria-label="Navigate to the Education section" href="#education" class="waves-effect waves-dark teal-text"><i
            class="mdi-social-school small"></i><span>Education</span></a>
      </li>
      <li class="bold">
        <a aria-label="Navigate to the Contact section" href="#contact" class="waves-effect waves-dark teal-text"><i
            class="mdi-content-mail small"></i><span>Contact</span></a>
      </li>
      <li class="bold">
        <a aria-label="Open Muhammad Naeem's Resume in a new tab"
          href="https://drive.google.com/file/d/1TNTF1wbQFVPmvTHlU4esKBYUdIIYN7ZH/view?usp=sharing" target="_blank"
          class="waves-effect waves-dark teal-text><i class="mdi-file-folder-open small"></i><span>Resume</span></a>
      </li>      
    </ul>
  </nav>

  <!-- Main Content-->
  <main>
    <!-- First Section: Heading lines and image -->
    <section id="intro" class="section scrollspy full-height">
      <div class="overlay"></div>
      <div class="container">
        <div class="col-md-9">
          <div class="content section-padding valign" style="margin-left: 10%; margin-top: 50px;">
            <div class="caption">
              <h2>Hi, I'm <span class="teal">Muhammad Naeem.</span></h2>
              <h5 style="color:#fff">A <span class="typing" style="font-weight: 300; color:#004d40"></span></h5>
              <!-- <h5 style="color:#00796b">A <span class="typing" style="font-weight: 300; color:#fff"></span></h5> -->
              <h5>Enthusiastic problem-solving programmer with a curious, can-do mindset, ready to tackle complex real-world challenges head-on.</h5>
            </div>
            <div class="social">
              <a href="https://www.linkedin.com/in/muhammadnaeem27/" target="_blank">
                <button class="icon-btn linkedin">
                  <i class="fa fa-linkedin"></i>
                </button>
              </a>
              <a href="https://github.com/muhammadnaeem27/" target="_blank">
                <button class="icon-btn github">
                  <i class="fa fa-github"></i>
                </button>
              </a>
            </div>
            <div class='buttons'>
              <a href="#about" class="readme">Read More</a>
              <a href="#contact" class="contactme">Contact Me</a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Second Section: About -->
    <section id="about" class="section scrollspy">
      <h3 class="page-title white-text teal">About</h3>
      <div class="container flow-text">
       
        <p>I am an AI Researcher and Computer Vision Specialist with expertise in object detection, segmentation, image generation, and 3D reconstruction, spanning both industry and academia.</p>
        <p>Currently, I am pursuing a Master’s in Photogrammetry and Remote Sensing at Wuhan University, China, under a fully funded scholarship. As part of <strong><a href="http://www.lmars.whu.edu.cn/en/" target="_blank">LIESMARS</a></strong> , my research direction is in 3D reconstruction and analysis using Gaussian Splatting and NeRF, under the supervision of <strong><a href="https://www.researchgate.net/profile/Xiongwu-Xiao" target="_blank">Prof. Xiongwu Xiao</a></strong>, focusing on deep learning for high-fidelity 3D modeling.</p>
        <p>Previously, I worked as a Senior AI Developer and Team Lead at Octaloop Technologies, leading the Computer Vision Team in projects like Virtual Room Staging, Virtual Try-on, and Video Game Streaming Highlights Generation, ensuring seamless AI integration and mentoring team members. 
        <p>I hold a Bachelor’s in Computer Science from COMSATS University, Islamabad, where I worked under <strong><a href="https://scholar.google.com.pk/citations?user=96XFWaUAAAAJ&hl=en" target="_blank">Dr. Jamal Hussain Shah</a></strong> on a weed classification web application, integrated into a robotic vehicle for laser-based weed elimination. This project fueled my passion for computer vision and AI-driven automation.</p>
        </p>
        <p>
          <ul>
            <li><b>Languages:</b> Python, C++, HTML/CSS, JavaScript</li>
            <li><b>Libraries:</b> NumPy, Pandas, OpenCV, Scikit-learn, Matplotlib, YOLO</li>
            <li><b>Frameworks:</b> PyTorch, Keras, TensorFlow, FastAPI, Bootstrap</li>
            <li><b>Tools & Technologies:</b> Git, Docker, AWS, GCP</li>
          </ul>
          
        </p>

        <p>
          I am deeply passionate about AI-driven innovation, constantly exploring new techniques to advance computer vision and 3D reconstruction while contributing to cutting-edge research.
        </p>

      </div>
    </section>


    <!-- Third Section: Experience -->
    <section id="experience" class="section scrollspy">
      <h3 class="page-title white-text teal">Experience</h3>
      <div class="container">

        <!-- Latest Experience  (Experience 2) -->
        <div class="card">
          <div class="card-content">
            <div class="row">
              <div class="col s12 m2">
                <a href="https://www.octaloop.io/" target="_blank"><img alt="Octaloop logo"
                    src="./assets/img/octaloop_logo.jpg" class="responsive-img center-block" /></a>
              </div>
              <!-- <div class="col s12 m10"> -->
              <div class="col s12 m10">
                <p>
                  <span class="card-title"><a href="https://www.octaloop.io/" target="_blank"
                      class="teal-text hoverline">Octaloop Technologies</a></span>
                </p>
              </div>
            </div>
            <div class="role brown-text text-darken-2">AI Developer / Team Lead</div>
            <ul>
              <li>Lead and oversee the Computer Vision Team, developing advanced solutions for projects such as Virtual Room Staging, Virtual Try-on and Video Game Streaming Highlights Generation using scene analysis.</li>
              <li>Supervise and mentor team members, ensuring seamless integration of AI functionalities into client applications and fostering a collaborative environment to drive innovation.</li>
              <li>Stay updated with the latest advancements in AI and computer vision, applying cutting-edge techniques to enhance project performance and client satisfaction.</li>
              <li><b>Tools:</b> Python, PyTorch, TensorFlow, YOLO, OpenCV, Keras, FastAPI, AWS, GCP</li>
            </ul>
          </div>
          <div class="card-action">
            <span>April 2024 -  Present | Islamabad, Pakistan</span>
          </div>
        </div>
        
        <!-- Recent Experience  (Experience 1) -->
        <div class="card">
          <div class="card-content">
            <div class="row">
              <div class="col s12 m2">
                <a href="https://www.ninesol.com/" target="_blank"><img alt="Ninesol logo"
                    src="./assets/img/ninesol_logo.jpg" class="responsive-img center-block" /></a>
              </div>
              <!-- <div class="col s12 m10"> -->
              <div class="col s12 m10">
                <p>
                  <span class="card-title"><a href="https://www.ninesol.com/" target="_blank"
                      class="teal-text hoverline">Ninesol Technologies</a></span>
                </p>
              </div>
            </div>
            <div class="role brown-text text-darken-2">AI Developer</div>
            <ul>
              <li>Developed and integrated the latest models into the backend of mobile and web applications, enhancing functionality with features such as Background Removal, Colorization, Document Scanning, Virtual Try-on, and Transcription as highlighted in my portfolio.</li>
              <li>Stayed informed with the latest industry trends and emerging technologies, applying this knowledge to refine and advance features within diverse applications.</li>
              <li>Collaborated with other team members to smoothly embed advanced functionalities, ensuring seamless user experiences in mobile applications.</li>
              <li><b>Tools:</b> Python, PyTorch, TensorFlow, YOLO, OpenCV, Keras, FastAPI, AWS, GCP</li>
            </ul>
          </div>
          <div class="card-action">
            <span>April 2023 -  April 2024 | Islamabad, Pakistan</span>
          </div>
        </div>


      </div>
    </section>

    <!-- Fourth Section: Projects -->
    <section id="projects" class="section scrollspy">
      <h3 class="page-title white-text teal">Projects</h3>
      <div class="container">
        <div class="row">

          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Virtual Staging" src="./assets/img/virtual_staging.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Virtual Staging <i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Implemented inpainting approach using Stable Diffusion to furnish empty rooms.
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title grey-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b>  Stable Diffusion, Controlnet, TensorFlow, FastApi, OpenCV, Colab, NumPy, Scikit-Learn  </li>
                  <li>Implemented an inpainting approach using Stable Diffusion with ControlNet to furnish empty room images without altering existing items and color combinations.</li>
                  <li>Applied semantic segmentation on empty rooms to identify areas and items to preserve, generating binary images from segmented masks.</li>
                  <li>Used tailored prompts for bedrooms and living rooms, passing binary masked images, prompts, and empty room images  to the Stable Diffusion inpainting model to generate furniture in the specified areas.</li>
                </ul>
<!--                 <div class="card-action">
                  <a aria-label="Visit the GitHub repo for  project" href="https://github.com/muhammadnaeem27/WeedBot_Agricultural_Weed_Detection"
                    target="_blank" data-position="top" data-tooltip="View Source"
                    class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i
                      class="fa fa-github"></i></a>
                </div> -->
              </div>
            </div>
          </div>
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Virtual Staging" src="./assets/img/highlights.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Video-games Streaming Highlight Generation <i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Generate highlights from large streaming videos.
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title grey-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b>  Python, PyTorch, OpenCV, NLTK, Scikit-Learn, FastApi </li>
                  <li>Developed a system to generate interesting highlights from 6-7 hours of video game streaming videos using three main approaches: Sound, Transcription, and Movement.</li>
                  <li>Implemented separate AI techniques for each approach to identify key timestamps, leveraging audio analysis, natural language processing, and computer vision.</li>
                  <li>Combined results from all three approaches in a specific sequence to produce the best highlights and generate a final video.</li>
                </ul>
<!--                 <div class="card-action">
                  <a aria-label="Visit the GitHub repo for  project" href="https://github.com/muhammadnaeem27/WeedBot_Agricultural_Weed_Detection"
                    target="_blank" data-position="top" data-tooltip="View Source"
                    class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i
                      class="fa fa-github"></i></a>
                </div> -->
              </div>
            </div>
          </div>
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Weed Detection" src="./assets/img/weed.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Weed Detection Robotic Car<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Created a robotic car for laser-based weed elimination 
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title grey-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b>  YOLO-v5, TensorFlow, Flask, Tkinter, VS code, Colab, Roboflow, labelimg  </li>
                  <li>Conducted interviews with farmers at the beginning of this project to compile a diverse dataset comprising four categories of weed. Implemented YOLO-v5 for real-time object detection, achieving precise identification of weeds in agricultural fields.</li>
                  <li>Designed and built a robotic car prototype that uses a smartphone camera and DC motors to wirelessly stream live images to the YOLO-v5 model via FastAPI. demonstrated a cutting-edge method of precision farming by integrating an Arduino-controlled LED system with a matrix-based system to precisely locate and eliminate weeds that were detected.</li>
                  <li>Created a website to showcase project insights, allowing users to engage with our trained YOLO-v5 model and evaluate its effectiveness.  Data visualization was used, highlighting the project's technological innovation and potential for sustainable agricultural practices. This included overall and daily weed detection percentages.</li>
                </ul>
                <div class="card-action">
                  <a aria-label="Visit the GitHub repo for  project" href="https://github.com/muhammadnaeem27/WeedBot_Agricultural_Weed_Detection"
                    target="_blank" data-position="top" data-tooltip="View Source"
                    class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i
                      class="fa fa-github"></i></a>
                </div>
              </div>
            </div>
          </div>
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Background (Remove or Change)" src="./assets/img/bg.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Portrait Background Remover<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Remove the background in portrait image
                </p>
              </div>
              <div class="card-reveal">
                <span class="card-title grey-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b>Python, PyTorch, U-Net, NumPy, Scikit-Learn, OpenCV</li>
                  <li>Using U-Net structures for both rough and detailed portrait segmentation, an intelligent two-segment Portrait Matting Model was used to address the problem of subject isolation in images.</li>
                  <li>The model's resolution limitations (below 2000x2000) and possible biases in the small amount of training data were acknowledged. Used the internet and publicly available datasets like COCO to find examples of portrait photos.</li>
   
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Gray Scale Image Colorizer" src="./assets/img/colorize.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Colorize Gray-scale Image<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Program for automatic colorization of grayscale images.
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title grey-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b> Python, PyTorch, Tensorflow,FastAPI, Colab, VS code</code></li>
                  <li>Included two time-scale update rules, self-attention GANs, and inflection points for effective and error-free coloring.</li>
                  <li>The U-Net architecture, which includes model-specific backbone choices (resnet34/resnet101), was utilized. It included spectral normalization and self-attention.</li>
                  <li>For realistic colorization free of artefacts, Perceptual Loss based on VGG16 was implemented during NoGAN learning.</li>
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <!-- Scrum -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Scrum" src="./assets/img/scrum.jpg"
                style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Teacher Assistant<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  A Scrum tool to automate the generation of Lecture reports, assignments,...
                </p>
              </div>
              <div class="card-reveal">
                <span class="card-title teal-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b> Python, Azure Speech Studio, GPT, PyAudio, Pyannote-Audio, Customtkinter, Firebase database, Firebase Authentication</li>
                  <li>Developed a transcription program utilizing PyAudio and Pyannote-Audio packages, ensuring precise speaker segmentation during the transcription process for both live audio streams and pre-recorded .wav files.</li>
                  <li>Used Customtkinter python package to create a simple educational interface that made it easier to add subjects, view lecture reports, and create assignments and quizzes based on lectures. </li>
                  <li>Firebase's secure cloud functionality was integrated, guaranteeing data security, and enabling features like email lecture report distribution to students for improved accessibility. </li>

                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <!-- Document Scanner -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Document Scanner" src="./assets/img/documentscanner.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Document Scanner<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Automated Document Scanning, Dewarping, and Structuring.
                </p>
              </div>
              <div class="card-reveal">
                <span class="card-title teal-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b> Python, OpenCV, PyTorch, Fast API, Colab, VS code</li>
                  <li>Led the creation of a Document Scanner with a Geometric Unwarping Transformer, using advanced algorithms from the Doc3D dataset for accurate geometric unwrapping of document images.</li>
                  <li>Using DocProj dataset, the Illumination Correction Transformer was able to resolve illumination problems during document scanning, which improved the quality of the images.</li>
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <!-- Sky change -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Sky Changer" src="./assets/img/skychange.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Sky Changer<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Change Sky in an image using reference sky image.
                </p>
              </div>
              <div class="card-reveal">
                <span class="card-title brown-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b> Python, PyTorch, UNET, Fast API, Colab, VS code</li>
                  <li>Sky Changer model consists of three main components: sky-changing (Multiband blender), high-res processing (UNET), and low-res processing (hrnet-ocr).</li>
                  <li>Enhanced segmentation in the low-res module by using ASPP. The learnable parameter high-resolution module performed better than the direct up sampling method. Using a Multiband blender, the sky-changing module effectively replaced the skies.</li>
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <!-- Image Generator -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="AI Art Generator" src="./assets/img/Aiart.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">AI Art Generator<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  An image generator based on the concept of Diffusion Models. 
                </p>
              </div>
              <div class="card-reveal">
                <span class="card-title brown-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li>Python, PyTorch, Hugging Face, Stable Diffusion, Fast API, Colab, VS code.</li>
                  <li>Implemented the Stable Diffusion model to implement a cutting-edge text-to-image generating project, making use of the Stable Diffusion pipeline to achieve the best possible results.</li>
                  <li>Used fine-tuning method on Stable Diffusion model to produce high-quality images customized for specific objects.</li>
                  <li>Using the Dreambooth technique, which trains on a small number of images of a subject or style, improved the text-to-image generation process' overall efficiency and creativity.</li>
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

          <!-- Face Swap -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Face Swap" src="./assets/img/faceswap.png" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Face Swap<i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Face Swap in an image using reference face image .
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title brown-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b> Python, Dlib, PyTorch, face-recognition, TensorFlow, Fast API, Colab, VS code</li>
                  <li>To ensure accurate and efficient face swapping, a model was implemented beforehand to ensure that the pose of the face in the source and target images were the same.</li>
                  <li>Used a package named Dlib to precisely identify facial points in both images, ensuring that the features were perfectly aligned.</li>
                  <li>Blended the faces together in a way to make sure the skin colors looked natural.</li>

                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>
          <!-- Talking Image -->
          <div class="col s12 m6 l4">
            <div class="card medium">
              <div class="card-image waves-effect waves-block waves-light">
                <img alt="Talking Image" src="./assets/img/talkingimg.gif" style="height: 100%; width: 100%" class="activator" />
              </div>
              <div class="card-content">
                <span class="card-title activator teal-text hoverline">Image to Talking Portrait <i
                    class="mdi-navigation-more-vert right"></i></span>
                <p>
                  Make talking portrait by using input image and reference audio.
                </p>
              </div>
              <div class="card-reveal">

                <span class="card-title brown-text"><small>Accomplishments</small><i
                    class="mdi-navigation-close right"></i></span>
                <ul>
                  <li><b>Tools:</b>Python, Dlib, face-recognition, PyTorch, ffmpeg, Dlib, Open-CV, Fast API, Colab, VS code</li>

                  <li>Created talking videos by smoothly combining the lips and head movements of a reference video with a source image. Dlib was put into use for accurate facial landmark identification and expression simulation.</li>

                  <li>Used Wav2Lip-hq for increased realism to ensure precise lip movement synchronization between the source image and the reference video. ESRGAN was integrated to up-sample the output video, which improved the visual quality.</li>
                  
                  <li>Designed a pipeline that integrates synchronized audio from the reference video to create finalized video. Used ffmpeg and OpenCV to process and compile videos efficiently.</li>
                </ul>
                <div class="card-action">

                </div>
              </div>
            </div>
          </div>

        </div>
      </div>
    </section>

    <!-- Fifth Section: Skills -->
    <section id="skills" class="section scrollspy">
      <h3 class="page-title white-text teal">Skills</h3>
      <div class="container">
        <div class="card">
          <div class="card-content">
            <h4 class="brown-text light">Languages and Databases</h4>
            <div class="row text-center">
              <div class="col s4 m2">
                <img alt="" src="./assets/img/python-logo-1-300x300.jpg" class="responsive-img" />Python
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/html5-300x300.jpg" class="responsive-img" />HTML5
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/css3-300x300.jpg" class="responsive-img" />CSS3
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/mysql-logo-1-300x300.jpg" class="responsive-img" />MySQL
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/c++.png" class="responsive-img" />C++
              </div>

              </div>
            </div>
          </div>
        </div>

        <div class="card">
          <div class="card-content">
            <h4 class="brown-text light">Libraries</h4>
            <div class="row text-center">
              <div class="col s4 m2">
                <img alt="" src="./assets/img/numpy-logo-1-500x500.jpg" class="responsive-img" />NumPy
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/pandas-logo-2-500x500.jpg" class="responsive-img" />Pandas
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/opencv-logo-1-500x500.jpg" class="responsive-img" />OpenCV
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/sk-learn-logo-1-500x500.jpg" class="responsive-img" />scikit-learn
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/matplotlib-logo-1-500x500.jpg" class="responsive-img" />matplotlib
              </div>
            </div>
          </div>
        </div>

        <!-- Frameworks -->
        <div class="card">
          <div class="card-content">
            <h4 class="brown-text light">Frameworks</h4>
            <div class="row text-center">

              <div class="col s4 m2">
                <img alt="" src="./assets/img/pytorch-logo.png" class="responsive-img" /> PyTorch
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/fastAPI.png" class="responsive-img" /> FastAPI
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/keras-logo.png" class="responsive-img" />Keras
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/tensorflow-logo-1.png" class="responsive-img" />TensorFlow
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/bootstrap.png" class="responsive-img" />Bootstrap
              </div>
            </div>
          </div>
        </div>

        <!-- Other -->
        <div class="card">
          <div class="card-content">
            <h4 class="brown-text light">Other</h4>
            <div class="row text-center">


              <div class="col s4 m2">
                <img alt="" src="./assets/img/git.png" class="responsive-img" />Git
              </div>
              <div class="col s4 m2">
                <img alt="" src="./assets/img/aws.png" class="responsive-img" />AWS
              </div>

            </div>
          </div>
        </div>



      </div>
    </section>

    <!-- Seventh Section: Education -->
    <section id="education" class="section scrollspy">
      <h3 class="page-title white-text teal">Education</h3>
      <div class="container">
        <div class="row">


            
          <div class="col s12 m6 l6">
            <div class="card">
              <div class="card-content">
                <p>
                  <span class="card-title"><a href="https://ahduni.edu.in/academics/schools-centres/school-of-engineering-and-applied-science/" target="_blank" class="teal-text hoverline">Comsats University Islamabad</a></span>
                </p>
                <p class="brown-text">Islamabad, Pakistan</p>
                <hr>
                <p>
                  <b>Degree: </b>Bachelor of Science in Computer Science
                  <br>
                  <b>CGPA: </b>3.13/4
                </p>

                <ul>
                  <p>
                    <b>Relevant Courseworks:</b>
                  <ul>
                    <li>Digital Image Processing</li>
                    <li>Computer Vision</li>
                    <li>Machine Learning</li>
                    <li>Pattern Recognition</li>
                    <li>Operating System</li>
                    <li>Data Structures and Algorithms</li>
                  </ul>
                  </p>

                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Eight Section: Contact -->
    <section id="contact" class="section scrollspy full-height">
      <h3 class="page-title white-text teal">Contact</h3>
      <div class="container">
        <p>
          <a aria-label="Call M.Naeem" data-position="top" data-tooltip="Call M.Naeem"
            class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i class="fa fa-phone"></i><a
              aria-label="Call M.Naeem">+923369279055</a></a>
        </p>
        <p>
          <a aria-label="Email M.Naeem" href="mailto:m.naeem4288@gmail.com" target="_blank" data-position="top"
            data-tooltip="Email M.Naeem" class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i
              class="fa fa-envelope"></i><a aria-label="Email M.Naeem" href="mailto:m.naeem4288@gmail.com"
              class="hoverline">m.naeem4288@gmail.com</a></a>
        </p>
        <p>
          <a aria-label="View M.Naeem on GitHub" href="https://github.com/muhammadnaeem27" target="_blank"
            data-position="top" data-tooltip="View M.Naeem on GitHub"
            class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i class="fa fa-github"></i><a
              aria-label="M.Naeem on Github" href="https://github.com/muhammadnaeem27" class="hoverline"
              target="_blank">muhammadnaeem27</a></a>
        </p>
        <p>
          <a aria-label="View M.Naeem on LinkedIn" href="https://www.linkedin.com/in/muhammadnaeem27/" target="_blank"
            data-position="top" data-tooltip="View M.Naeem on LinkedIn"
            class="btn-floating btn-large waves-effect waves-light blue-grey tooltipped"><i
              class="fa fa-linkedin"></i><a aria-label="M.Naeem on LinkedIn" href="https://www.linkedin.com/in/muhammadnaeem27/"
              class="hoverline" target="_blank">muhammadnaeem27</a></a>
        </p>
      </div>
    </section>
  </main>

  <!-- typed.js -->
  <script src="./assets/vendor/typed.js/typed.min.js"></script>
  <script type="text/javascript">
    var typed = new Typed('.typing',{
      strings: ["Pythonist", "Developer", "Fast Learner"],
      loop: true,
      typeSpeed: 80,
      backSpeed: 40
    });
  </script>


  <!-- jQuery-->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>

  <!-- Materialize - Compiled and minified JavaScript-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.95.3/js/materialize.min.js"></script>
  <script>
    // Materialize - Initializers
    $(document).ready(function () {
      $(".scrollspy").scrollSpy()
      // Initialize collapse button
      $(".button-collapse").sideNav({
        menuWidth: 190, // Default is 240
        edge: "left", // Choose the horizontal origin
        closeOnClick: true // Closes side-nav on <a> clicks, useful for Angular/Meteor
      })
    })
  </script>
</body>

</html>
